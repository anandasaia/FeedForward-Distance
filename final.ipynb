{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2351f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas scikit-learn tensorflow opencv-python opencv-contrib-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fcdb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the annotations.csv file\n",
    "annotations = pd.read_csv('annotations.csv')\n",
    "\n",
    "# Extract the required input features and output\n",
    "X = annotations[['xmin', 'ymin', 'xmax', 'ymax', 'xloc', 'yloc', 'observation angle']]\n",
    "y = annotations['zloc']\n",
    "\n",
    "# Normalize the input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d713f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82257c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(150, activation='relu', input_shape=(7,)),\n",
    "    tf.keras.layers.Dense(150, activation='relu'),\n",
    "    tf.keras.layers.Dense(150, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Create the training_epochs folder if it doesn't exist\n",
    "if not os.path.exists('training_epochs'):\n",
    "    os.makedirs('training_epochs')\n",
    "\n",
    "# Create a ModelCheckpoint callback to save the model after every 100 epochs\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='training_epochs/trained_model_epoch_{epoch:04d}.h5',\n",
    "    save_freq=100 * len(X_train) // 32,  # Save after every 100 epochs\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=3000,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=2,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0edc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(150, activation='relu', input_shape=(7,)),\n",
    "    tf.keras.layers.Dense(150, activation='relu'),\n",
    "    tf.keras.layers.Dense(150, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Create the training_epochs folder if it doesn't exist\n",
    "if not os.path.exists('training_epochs'):\n",
    "    os.makedirs('training_epochs')\n",
    "\n",
    "epochs_list = [100]\n",
    "validation_losses = []\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    # Create a ModelCheckpoint callback to save the model after every specified number of epochs\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'training_epochs/trained_model_{epochs:04d}.h5',\n",
    "        save_freq=100,\n",
    "        save_weights_only=False,\n",
    "        save_best_only=False\n",
    "    )\n",
    "\n",
    "    # Train the model for the specified number of epochs\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=2,\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "\n",
    "    # Plot the validation loss history\n",
    "    plt.plot(history.history['val_loss'], label=f'{epochs} Epochs')\n",
    "    validation_losses.append(history.history['val_loss'][-1])\n",
    "\n",
    "    # Save the validation loss graph\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'metrics/validation_loss_{epochs:04d}.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(150, activation='relu', input_shape=(7,)),\n",
    "    tf.keras.layers.Dense(150, activation='relu'),\n",
    "    tf.keras.layers.Dense(150, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Create the training_epochs folder if it doesn't exist\n",
    "if not os.path.exists('training_epochs'):\n",
    "    os.makedirs('training_epochs')\n",
    "\n",
    "epochs_list = [3000]\n",
    "validation_losses = []\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    # Create a ModelCheckpoint callback to save the model after every specified number of epochs\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'training_epochs/trained_model_{epochs:04d}.h5',\n",
    "        save_freq=100,\n",
    "        save_weights_only=False,\n",
    "        save_best_only=False\n",
    "    )\n",
    "\n",
    "    # Train the model for the specified number of epochs\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=2,\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "\n",

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the epochs for which you want to plot the MAE\n",
    "epochs = [100, 500, 1000, 2000]\n",
    "\n",
    "# Create empty lists to store the MAE values for each epoch\n",
    "mae_values = []\n",
    "\n",
    "# Iterate over the epochs\n",
    "for epoch in epochs:\n",
    "    # Load the trained model for the specific epoch\n",
    "    model.load_weights(f'training_epochs/trained_model_{epoch}.h5')\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    # Append the MAE value to the list\n",
    "    mae_values.append(mae)\n",
    "\n",
    "# Plot the MAE values\n",
    "plt.plot(epochs, mae_values, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.title('MAE for Different Epochs')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c6b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model with the final number of epochs\n",
    "\"\"\"final_epochs = 2000\n",
    "final_history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=final_epochs,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=2\n",
    ")\"\"\"\n",
    "model = tf.keras.models.load_model('training_epochs/trained_model_2000.h5')\n",
    "\n",
    "# Generate performance metrics for the final model\n",
    "y_pred = model.predict(X_test)\n",
    "abs_error = mean_absolute_error(y_test, y_pred)\n",
    "rel_error = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Create a table with performance metrics\n",
    "metrics_table = pd.DataFrame({\n",
    "    'Metric': ['Absolute Error', 'Relative Error', 'Mean Absolute Percentage Error', 'Mean Absolute Error', 'R2 Score'],\n",
    "    'Value': [abs_error, rel_error, mape, mae, r2]\n",
    "})\n",
    "\n",
    "# Save the metrics table as a CSV file\n",
    "metrics_table.to_csv('metrics/metrics_table.csv', index=False)\n",
    "\n",
    "# Save the metrics table as a PNG image\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.axis('off')\n",
    "plt.table(cellText=metrics_table.values,\n",
    "          colLabels=metrics_table.columns,\n",
    "          cellLoc='center',\n",
    "          loc='center')\n",
    "plt.savefig('metrics/metrics_table.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot the graph showing the metrics relative to the number of epochs\n",
    "metrics = {\n",
    "    'Absolute Error': [],\n",
    "    'Relative Error': [],\n",
    "    'Mean Absolute Percentage Error': [],\n",
    "    'Mean Absolute Error': [],\n",
    "    'R2 Score': []\n",
    "}\n",
    "\n",
    "for i, epochs in enumerate(epochs_list):\n",
    "    metrics['Absolute Error'].append(mean_absolute_error(y_test, model.predict(X_test, batch_size=32)))\n",
    "    metrics['Relative Error'].append(mean_absolute_percentage_error(y_test, model.predict(X_test, batch_size=32)))\n",
    "    metrics['Mean Absolute Percentage Error'].append(mean_absolute_percentage_error(y_test, model.predict(X_test, batch_size=32)))\n",
    "    metrics['Mean Absolute Error'].append(mean_absolute_error(y_test, model.predict(X_test, batch_size=32)))\n",
    "    metrics['R2 Score'].append(r2_score(y_test, model.predict(X_test, batch_size=32)))\n",
    "\n",
    "metrics['Absolute Error'].append(abs_error)\n",
    "metrics['Relative Error'].append(rel_error)\n",
    "metrics['Mean Absolute Percentage Error'].append(mape)\n",
    "metrics['Mean Absolute Error'].append(mae)\n",
    "metrics['R2 Score'].append(r2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for metric, values in metrics.items():\n",
    "    plt.plot(epochs_list[:i+1] + [final_epochs], values[:i+1] + [values[-1]], marker='o')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Metrics')\n",
    "plt.xticks(epochs_list + [final_epochs])\n",
    "plt.legend(metrics.keys())\n",
    "plt.savefig('metrics/metrics_graph.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c51a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('trained_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ae951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ee585",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yolov3-tf2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.load_model('trained_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52032cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def detect_objects(image, model, scaler):\n",
    "    # Load the YOLOv3 model\n",
    "    net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
    "\n",
    "    # Get the output layer names\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "    # Prepare the input image\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Run the forward pass\n",
    "    layer_outputs = net.forward(output_layers)\n",
    "\n",
    "    # Extract the detected objects and their bounding boxes, camera coordinates, and observation angles\n",
    "    objects = []\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                # Get the bounding box coordinates\n",
    "                center_x, center_y, width, height = (detection[0:4] * np.array([image.shape[1], image.shape[0], image.shape[1], image.shape[0]])).astype('int')\n",
    "                xmin, ymin = int(center_x - width / 2), int(center_y - height / 2)\n",
    "                xmax, ymax = int(center_x + width / 2), int(center_y + height / 2)\n",
    "\n",
    "                # Get the camera coordinates and observation angle\n",
    "                xloc, yloc = center_x / image.shape[1], center_y / image.shape[0]\n",
    "                observation_angle = np.arctan2(yloc, xloc)\n",
    "\n",
    "                # Prepare the input for the multilayer perceptron model\n",
    "                input_data = np.array([[xmin, ymin, xmax, ymax, xloc, yloc, observation_angle]])\n",
    "                input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "                # Predict the distance using the trained model\n",
    "                zloc = model.predict(input_data_scaled)[0][0]\n",
    "\n",
    "                # Store the detected object information\n",
    "                objects.append({\n",
    "                    'class_id': class_id,\n",
    "                    'confidence': confidence,\n",
    "                    'bounding_box': (xmin, ymin, xmax, ymax),\n",
    "                    'camera_coordinates': (xloc, yloc),\n",
    "                    'observation_angle': observation_angle,\n",
    "                    'zloc': zloc\n",
    "                })\n",
    "\n",
    "    return objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb8e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(input_path, output_path, mode):\n",
    "    # Load the class names\n",
    "    with open('yolov3.names', 'r') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # Get the list of files in the input directory\n",
    "    input_files = [os.path.join(input_path, f) for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "\n",
    "    # Define the confidence and NMS thresholds\n",
    "    CONF_THRESHOLD = 0.1  # Increase this value to reduce false positives\n",
    "    NMS_THRESHOLD = 0.1   # Increase this value to allow more overlap between bounding boxes\n",
    "    \n",
    "    for input_file in input_files:\n",
    "        # Read the input image or video\n",
    "        if mode == 'image':\n",
    "            image = cv2.imread(input_file)\n",
    "            # Detect objects and draw the bounding boxes, class names, and distances\n",
    "            objects = detect_objects(image, model, scaler)\n",
    "            indices = cv2.dnn.NMSBoxes([obj['bounding_box'] for obj in objects], [obj['confidence'] for obj in objects], CONF_THRESHOLD, NMS_THRESHOLD)\n",
    "\n",
    "            for index in indices.flatten():\n",
    "                obj = objects[index]\n",
    "                xmin, ymin, xmax, ymax = obj['bounding_box']\n",
    "                class_name = classes[obj['class_id']]\n",
    "                distance = obj['zloc']\n",
    "                cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                cv2.putText(image, f'{class_name} {distance:.2f}m', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.imwrite(os.path.join(output_path, os.path.basename(input_file)), image)\n",
    "        elif mode == 'video':\n",
    "            cap = cv2.VideoCapture(input_file)\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(os.path.join(output_path, os.path.basename(input_file)), fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "            while cap.isOpened():\n",
    "                ret, image = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                # Detect objects and draw the bounding boxes, class names, and distances\n",
    "                objects = detect_objects(image, model, scaler)\n",
    "                indices = cv2.dnn.NMSBoxes([obj['bounding_box'] for obj in objects], [obj['confidence'] for obj in objects], CONF_THRESHOLD, NMS_THRESHOLD)\n",
    "                for index in indices.flatten():\n",
    "                    obj = objects[index]\n",
    "                    xmin, ymin, xmax, ymax = obj['bounding_box']\n",
    "                    class_name = classes[obj['class_id']]\n",
    "                    distance = obj['zloc']\n",
    "                    cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                    cv2.putText(image, f'{class_name} {distance:.2f}m', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                out.write(image)\n",
    "            cap.release()\n",
    "            out.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_webcam():\n",
    "    # Load the class names\n",
    "    with open('yolov3.names', 'r') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # Define the confidence and NMS thresholds\n",
    "    CONF_THRESHOLD = 0.6  # Increase this value to reduce false positives\n",
    "    NMS_THRESHOLD = 0.5   # Increase this value to allow more overlap between bounding boxes\n",
    "\n",
    "    # Open the webcam\n",
    "    cap = cv2.VideoCapture(-1)\n",
    "\n",
    "    while True:\n",
    "        # Capture a frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Detect objects and draw the bounding boxes, class names, and distances\n",
    "        objects = detect_objects(frame, model, scaler)\n",
    "        indices = cv2.dnn.NMSBoxes([obj['bounding_box'] for obj in objects], [obj['confidence'] for obj in objects], CONF_THRESHOLD, NMS_THRESHOLD)\n",
    "        #indices = cv2.dnn.NMSBoxes([obj['bounding_box'] for obj in objects], [obj['confidence'] for obj in objects])\n",
    "\n",
    "        for index in indices.flatten():\n",
    "            obj = objects[index]\n",
    "            xmin, ymin, xmax, ymax = obj['bounding_box']\n",
    "            class_name = classes[obj['class_id']]\n",
    "            distance = obj['zloc']\n",
    "\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'{class_name} {distance:.1f}m', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Webcam', frame)\n",
    "\n",
    "        # Exit the loop if the 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f406f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "mode = 'image'  # Change this to 'image' or 'video' to process images or videos from a folder\n",
    "\n",
    "if mode == 'webcam':\n",
    "    process_webcam()\n",
    "else:\n",
    "    input_path = 'testt'\n",
    "    output_path = 'results_img'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    process_files(input_path, output_path, mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3bb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7013388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b793d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
